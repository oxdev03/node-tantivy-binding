/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

/** Get the version of the library */
export declare function getVersion(): string
/** Text field indexing options */
export interface TextFieldOptions {
  /** Store the field value (can be retrieved from search results) */
  stored?: boolean
  /** Fast field access (column-oriented storage) */
  fast?: boolean
  /** Tokenizer name to use (default: "default") */
  tokenizerName?: string
  /** Index record option: "basic", "freq", or "position" (default: "position") */
  indexOption?: string
}
/** Numeric field options (for integers, floats, dates) */
export interface NumericFieldOptions {
  /** Store the field value (can be retrieved from search results) */
  stored?: boolean
  /** Index the field (enables searching) */
  indexed?: boolean
  /** Fast field access (column-oriented storage) */
  fast?: boolean
}
/** Bytes field options */
export interface BytesFieldOptions {
  /** Store the field value (can be retrieved from search results) */
  stored?: boolean
  /** Index the field (enables searching) */
  indexed?: boolean
  /** Fast field access (column-oriented storage) */
  fast?: boolean
}
/** IP address field options */
export interface IpAddrFieldOptions {
  /** Store the field value (can be retrieved from search results) */
  stored?: boolean
  /** Index the field (enables searching) */
  indexed?: boolean
  /** Fast field access (column-oriented storage) */
  fast?: boolean
}
/** Tantivy's FieldType */
export const enum FieldType {
  Str = 0,
  U64 = 1,
  I64 = 2,
  F64 = 3,
  Bool = 4,
  Date = 5,
  Facet = 6,
  Bytes = 7,
  JsonObject = 8,
  IpAddr = 9,
}
/** Represents a Tantivy Occur type for BooleanQuery */
export const enum Occur {
  Must = 0,
  Should = 1,
  MustNot = 2,
}
/** Enum representing the direction in which something should be sorted. */
export const enum Order {
  /** Ascending. Smaller values appear first. */
  Asc = 0,
  /** Descending. Larger values appear first. */
  Desc = 1,
}
/** Object holding a results successful search. */
export interface SearchResult {
  hits: Array<SearchHit>
  /**
   * How many documents matched the query. Only available if `count` was set
   * to true during the search.
   */
  count?: number
}
export interface SearchHit {
  score?: number
  order?: number
  docAddress: DocAddress
}
/**
 * DocAddress contains all the necessary information to identify a document
 * given a Searcher object.
 *
 * It consists in an id identifying its segment, and its segment-local DocId.
 * The id used for the segment is actually an ordinal in the list of segment
 * hold by a Searcher.
 */
export interface DocAddress {
  segmentOrd: number
  doc: number
}
export interface Range {
  start: number
  end: number
}
/**
 * A SchemaBuilder can be used to create a Schema.
 *
 * The schema will list all the fields and associated types and options.
 *
 * Example:
 * ```javascript
 * const builder = new SchemaBuilder();
 * builder.addTextField("title", { stored: true });
 * builder.addTextField("body", { stored: false });
 * builder.addIntegerField("year", { stored: true, indexed: true });
 * const schema = builder.build();
 * ```
 */
export declare class SchemaBuilder {
  /** Create a new SchemaBuilder. */
  constructor()
  /**
   * Check if a field name is valid.
   *
   * @param name - The field name to validate
   * @returns True if the field name is valid
   */
  static isValidFieldName(name: string): boolean
  /**
   * Add a text field to the schema.
   *
   * @param name - The name of the field
   * @param options - Text field options
   * @returns Self for method chaining
   */
  addTextField(name: string, options?: TextFieldOptions | undefined | null): this
  /**
   * Add a signed integer field to the schema.
   *
   * @param name - The name of the field
   * @param options - Numeric field options
   * @returns Self for method chaining
   */
  addIntegerField(name: string, options?: NumericFieldOptions | undefined | null): this
  /**
   * Add an unsigned integer field to the schema.
   *
   * @param name - The name of the field
   * @param options - Numeric field options
   * @returns Self for method chaining
   */
  addUnsignedField(name: string, options?: NumericFieldOptions | undefined | null): this
  /**
   * Add a float field to the schema.
   *
   * @param name - The name of the field
   * @param options - Numeric field options
   * @returns Self for method chaining
   */
  addFloatField(name: string, options?: NumericFieldOptions | undefined | null): this
  /**
   * Add a boolean field to the schema.
   *
   * @param name - The name of the field
   * @param options - Numeric field options
   * @returns Self for method chaining
   */
  addBooleanField(name: string, options?: NumericFieldOptions | undefined | null): this
  /**
   * Add a date field to the schema.
   *
   * @param name - The name of the field
   * @param options - Numeric field options
   * @returns Self for method chaining
   */
  addDateField(name: string, options?: NumericFieldOptions | undefined | null): this
  /**
   * Add a JSON field to the schema.
   *
   * @param name - The name of the field
   * @param options - JSON field options
   * @returns Self for method chaining
   */
  addJsonField(name: string, options?: JsonFieldOptions | undefined | null): this
  /**
   * Add a facet field to the schema.
   *
   * @param name - The name of the field
   * @returns Self for method chaining
   */
  addFacetField(name: string): this
  /**
   * Add a bytes field to the schema.
   *
   * @param name - The name of the field
   * @param options - Bytes field options
   * @returns Self for method chaining
   */
  addBytesField(name: string, options?: BytesFieldOptions | undefined | null): this
  /**
   * Add an IP address field to the schema.
   *
   * @param name - The name of the field
   * @param options - IP address field options
   * @returns Self for method chaining
   */
  addIpAddrField(name: string, options?: IpAddrFieldOptions | undefined | null): this
  /**
   * Build the final schema.
   *
   * After calling this method, the SchemaBuilder can no longer be used.
   *
   * @returns The built schema
   */
  build(): Schema
}
/**
 * Tantivy schema.
 *
 * The schema is very strict. To build the schema the `SchemaBuilder` class is
 * provided.
 */
export declare class Schema {}
/**
 * Tantivy's Document is the object that can be indexed and then searched for.
 *
 * Documents are fundamentally a collection of unordered tuples
 * (field_name, value). In this list, one field may appear more than once.
 *
 * Example:
 * ```javascript
 * const doc = new Document();
 * doc.addText("title", "The Old Man and the Sea");
 * doc.addText("body", "He was an old man who fished alone in a skiff...");
 * ```
 */
export declare class Document {
  /** Creates a new document. */
  constructor()
  /**
   * Extend the document with values from a dictionary.
   *
   * @param dict - Object containing field names and values to add
   * @param schema - Optional schema for type validation
   */
  extend(dict: object, schema?: Schema | undefined | null): void
  /**
   * Create a document from a dictionary with optional schema.
   *
   * @param dict - Object containing field names and values
   * @param schema - Optional schema for type validation
   */
  static fromDict(dict: object, schema?: Schema | undefined | null): Document
  /**
   * Returns a dictionary with the different
   * field values.
   */
  toDict(): object
  /**
   * Add a text value to the document.
   *
   * @param field_name - The field name for which we are adding the text.
   * @param text - The text that will be added to the document.
   */
  addText(fieldName: string, text: string): void
  /**
   * Add an unsigned integer value to the document.
   *
   * @param field_name - The field name for which we are adding the unsigned integer.
   * @param value - The integer that will be added to the document.
   */
  addUnsigned(fieldName: string, value: number): void
  /**
   * Add a signed integer value to the document.
   *
   * @param field_name - The field name for which we are adding the integer.
   * @param value - The integer that will be added to the document.
   */
  addInteger(fieldName: string, value: number): void
  /**
   * Add a float value to the document.
   *
   * @param field_name - The field name for which we are adding the value.
   * @param value - The float that will be added to the document.
   */
  addFloat(fieldName: string, value: number): void
  /**
   * Add a boolean value to the document.
   *
   * @param field_name - The field name for which we are adding the value.
   * @param value - The boolean that will be added to the document.
   */
  addBoolean(fieldName: string, value: boolean): void
  /**
   * Add a date value to the document.
   *
   * @param field_name - The field name for which we are adding the date.
   * @param value - The date as a string in RFC 3339 format or a Unix timestamp (in seconds).
   */
  addDate(fieldName: string, value: string): void
  /**
   * Add a facet value to the document.
   * @param field_name - The field name for which we are adding the facet.
   * @param value - The Facet that will be added to the document.
   */
  addFacet(fieldName: string, facetPath: string): void
  /**
   * Add a bytes value to the document.
   *
   * @param field_name - The field for which we are adding the bytes.
   * @param value - The bytes that will be added to the document.
   */
  addBytes(fieldName: string, bytes: Buffer): void
  /**
   * Add a JSON value to the document.
   *
   * @param field_name - The field for which we are adding the JSON.
   * @param value - The JSON object as a string or object.
   */
  addJson(fieldName: string, value: object): void
  /**
   * Add an IP address value to the document.
   *
   * @param field_name - The field for which we are adding the IP address.
   * @param value - The IP address object that will be added to the document.
   */
  addIpAddr(fieldName: string, value: string): void
  /** Returns the number of added fields that have been added to the document */
  get numFields(): number
  /** True if the document is empty, False otherwise. */
  get isEmpty(): boolean
  /**
   * Get the first value associated with the given field.
   *
   * @param field_name - The field for which we would like to get the value.
   * @returns The value if one is found, otherwise null.
   */
  getFirst(fieldName: string): unknown
  /**
   * Get the all values associated with the given field.
   *
   * @param field_name - The field for which we would like to get the values.
   * @returns A list of values.
   */
  getAll(fieldName: string): object
}
/** Tantivy's Query */
export declare class Query {
  toString(): string
  /** Construct a Tantivy's TermQuery */
  static termQuery(
    schema: Schema,
    fieldName: string,
    fieldValue: unknown,
    indexOption?: string | undefined | null,
  ): Query
  /** Construct a Tantivy's TermSetQuery */
  static termSetQuery(schema: Schema, fieldName: string, fieldValues: Array<unknown>): Query
  /** Construct a Tantivy's AllQuery */
  static allQuery(): Query
  /**
   * Construct a Tantivy's FuzzyTermQuery
   *
   * # Arguments
   *
   * * `schema` - Schema of the target index.
   * * `field_name` - Field name to be searched.
   * * `text` - String representation of the query term.
   * * `distance` - (Optional) Edit distance you are going to alow. When not specified, the default is 1.
   * * `transposition_cost_one` - (Optional) If true, a transposition (swapping) cost will be 1; otherwise it will be 2. When not specified, the default is true.
   * * `prefix` - (Optional) If true, prefix levenshtein distance is applied. When not specified, the default is false.
   */
  static fuzzyTermQuery(
    schema: Schema,
    fieldName: string,
    text: string,
    distance?: number | undefined | null,
    transpositionCostOne?: boolean | undefined | null,
    prefix?: boolean | undefined | null,
  ): Query
  /**
   * Construct a Tantivy's PhraseQuery with custom offsets and slop
   *
   * # Arguments
   *
   * * `schema` - Schema of the target index.
   * * `field_name` - Field name to be searched.
   * * `words` - Word list that constructs the phrase. A word can be a term text or a pair of term text and its offset in the phrase.
   * * `slop` - (Optional) The number of gaps permitted between the words in the query phrase. Default is 0.
   */
  static phraseQuery(schema: Schema, fieldName: string, words: Array<unknown>, slop?: number | undefined | null): Query
  /** Construct a Tantivy's BooleanQuery */
  static booleanQuery(subqueries: Array<object>): Query
  /** Construct a Tantivy's DisjunctionMaxQuery */
  static disjunctionMaxQuery(subqueries: Array<Query>, tieBreaker?: number | undefined | null): Query
  /** Construct a Tantivy's BoostQuery */
  static boostQuery(query: Query, boost: number): Query
  /** Construct a Tantivy's RegexQuery */
  static regexQuery(schema: Schema, fieldName: string, regexPattern: string): Query
  static moreLikeThisQuery(
    docAddress: DocAddress,
    minDocFrequency?: number | undefined | null,
    maxDocFrequency?: number | undefined | null,
    minTermFrequency?: number | undefined | null,
    maxQueryTerms?: number | undefined | null,
    minWordLength?: number | undefined | null,
    maxWordLength?: number | undefined | null,
    boostFactor?: number | undefined | null,
    stopWords?: Array<string> | undefined | null,
  ): Query
  /** Construct a Tantivy's ConstScoreQuery */
  static constScoreQuery(query: Query, score: number): Query
  static rangeQuery(
    schema: Schema,
    fieldName: string,
    fieldType: FieldType,
    lowerBound: unknown,
    upperBound: unknown,
    includeLower?: boolean | undefined | null,
    includeUpper?: boolean | undefined | null,
  ): Query
  /**
   * Explain how this query matches a given document.
   *
   * This method provides detailed information about how the document matched the query
   * and how the score was calculated.
   *
   * # Arguments
   * * `searcher` - The searcher used to perform the search
   * * `doc_address` - The address of the document to explain
   *
   * # Returns
   * * `Explanation` - An object containing detailed scoring information
   */
  explain(searcher: Searcher, docAddress: DocAddress): Explanation
}
/**
 * Tantivy's Searcher class
 *
 * A Searcher is used to search the index given a prepared Query.
 */
export declare class Searcher {
  /**
   * Search the index with the given query and collect results.
   *
   * Args:
   *     query (Query): The query that will be used for the search.
   *     limit (int, optional): The maximum number of search results to
   *         return. Defaults to 10.
   *     count (bool, optional): Should the number of documents that match
   *         the query be returned as well. Defaults to true.
   *     order_by_field (Field, optional): A schema field that the results
   *         should be ordered by. The field must be declared as a fast field
   *         when building the schema. Note, this only works for unsigned
   *         fields.
   *     offset (Field, optional): The offset from which the results have
   *         to be returned.
   *     order (Order, optional): The order in which the results
   *         should be sorted. If not specified, defaults to descending.
   *
   * Returns `SearchResult` object.
   *
   * Raises a ValueError if there was an error with the search.
   */
  search(
    query: Query,
    limit?: number | undefined | null,
    count?: boolean | undefined | null,
    orderByField?: string | undefined | null,
    offset?: number | undefined | null,
    order?: Order | undefined | null,
  ): SearchResult
  aggregate(query: Query, agg: unknown): string
  /** Returns the overall number of documents in the index. */
  get numDocs(): number
  /** Returns the number of segments in the index. */
  get numSegments(): number
  /**
   * Return the overall number of documents containing
   * the given term.
   */
  docFreq(fieldName: string, fieldValue: unknown): number
  /**
   * Fetches a document from Tantivy's store given a DocAddress.
   *
   * Args:
   *     doc_address (DocAddress): The DocAddress that is associated with
   *         the document that we wish to fetch.
   *
   * Returns the Document, raises ValueError if the document can't be found.
   */
  doc(docAddress: DocAddress): Document
}
/**
 * Tantivy Snippet
 *
 * Snippet contains a fragment of a document, and some highlighted
 * parts inside it.
 */
export declare class Snippet {
  toHtml(): string
  highlighted(): Array<Range>
  fragment(): string
}
export declare class SnippetGenerator {
  static create(searcher: Searcher, query: Query, schema: Schema, fieldName: string): SnippetGenerator
  snippetFromDoc(doc: Document): Snippet
  setMaxNumChars(maxNumChars: number): void
}
export declare class Tokenizer {}
export declare class TokenizerStatic {
  /** SimpleTokenizer */
  static simple(): Tokenizer
  /** WhitespaceTokenizer */
  static whitespace(): Tokenizer
  /** Raw Tokenizer */
  static raw(): Tokenizer
  /** FacetTokenizer */
  static facet(): Tokenizer
  /** Regextokenizer */
  static regex(pattern: string): Tokenizer
  /**
   * NgramTokenizer
   *
   * Args:
   * - min_gram (number): Minimum character length of each ngram.
   * - max_gram (number): Maximum character length of each ngram.
   * - prefix_only (boolean, optional): If true, ngrams must count from the start of the word.
   */
  static ngram(
    minGram?: number | undefined | null,
    maxGram?: number | undefined | null,
    prefixOnly?: boolean | undefined | null,
  ): Tokenizer
}
export declare class Filter {}
export declare class FilterStatic {
  /** AlphaNumOnlyFilter */
  static alphanumOnly(): Filter
  /** AsciiFoldingFilter */
  static asciiFold(): Filter
  static lowercase(): Filter
  /**
   * RemoveLongFilter
   *
   * Args:
   * - length_limit (number): max character length of token.
   */
  static removeLong(lengthLimit: number): Filter
  /** Stemmer */
  static stemmer(language: string): Filter
  /**
   * StopWordFilter (builtin stop word list)
   *
   * Args:
   * - language (string): Stop words list language.
   *   Valid values: {
   *     "arabic", "danish", "dutch", "english", "finnish", "french", "german", "greek",
   *     "hungarian", "italian", "norwegian", "portuguese", "romanian", "russian",
   *     "spanish", "swedish", "tamil", "turkish"
   *   }
   */
  static stopword(language: string): Filter
  /**
   * StopWordFilter (user-provided stop word list)
   *
   * This variant of Filter.stopword() lets you provide
   * your own custom list of stopwords.
   *
   * Args:
   * - stopwords (Array<string>): a list of words to be removed.
   */
  static customStopword(stopwords: Array<string>): Filter
  /**
   * SplitCompoundWords
   *
   * https://docs.rs/tantivy/latest/tantivy/tokenizer/struct.SplitCompoundWords.html
   *
   * Args:
   * - constituent_words (Array<string>): words that make up compound word (must be in order).
   *
   * Example:
   *
   * ```javascript
   * // useless, contrived example:
   * compound_spliter = Filter.splitCompound(['butter', 'fly'])
   * // Will split 'butterfly' -> ['butter', 'fly'],
   * // but won't split 'buttering' or 'buttercupfly'
   * ```
   */
  static splitCompound(constituentWords: Array<string>): Filter
}
/**
 * Tantivy's TextAnalyzer
 *
 * Do not instantiate this class directly.
 * Use the `TextAnalyzerBuilder` class instead.
 */
export declare class TextAnalyzer {
  /**
   * Tokenize a string
   * Args:
   * - text (string): text to tokenize.
   * Returns:
   * - Array<string>: a list of tokens/words.
   */
  analyze(text: string): Array<string>
}
/**
 * Tantivy's TextAnalyzerBuilder
 *
 * # Example
 *
 * ```javascript
 * my_analyzer = new TextAnalyzerBuilder(Tokenizer.simple())
 *     .filter(Filter.lowercase())
 *     .filter(Filter.ngram())
 *     .build()
 * ```
 *
 * https://docs.rs/tantivy/latest/tantivy/tokenizer/struct.TextAnalyzerBuilder.html
 */
export declare class TextAnalyzerBuilder {
  constructor(tokenizer: Tokenizer)
  /**
   * Add filter to the builder.
   *
   * Args:
   * - filter (Filter): a Filter object.
   * Returns:
   * - TextAnalyzerBuilder: A new instance of the builder
   *
   * Note: The builder is _not_ mutated in-place.
   */
  filter(filter: Filter): TextAnalyzerBuilder
  /**
   * Build final TextAnalyzer object.
   *
   * Returns:
   * - TextAnalyzer with tokenizer and filters baked in.
   *
   * Tip: TextAnalyzer's `analyze(text) -> tokens` method lets you
   * easily check if your analyzer is working as expected.
   */
  build(): TextAnalyzer
}
/** Error in the query syntax. */
export declare class SyntaxError {
  get innerMessage(): string
  toString(): string
}
/** This query is unsupported. */
export declare class UnsupportedQueryError {
  get innerMessage(): string
  toString(): string
}
/** The query references a field that is not in the schema. */
export declare class FieldDoesNotExistError {
  /** The name of the field causing the error. */
  get field(): string
  toString(): string
}
/** The query contains a term for a `u64` or `i64`-field, but the value is neither. */
export declare class ExpectedIntError {
  /** If `true`, the value being parsed was empty. */
  causedByEmpty(): boolean
  /** If `true`, an invalid digit was found. */
  causedByInvalidDigit(): boolean
  /** If `true`, the value being parsed was too large. */
  causedByPosOverflow(): boolean
  /** If `true`, the value being parsed was too small. */
  causedByNegOverflow(): boolean
  toString(): string
}
/** The query contains a term for a bytes field, but the value is not valid base64. */
export declare class ExpectedBase64Error {
  /**
   * If `true`, an invalid byte was found in the query. Padding characters (`=`) interspersed in
   * the encoded form will be treated as invalid bytes.
   */
  causedByInvalidByte(): boolean
  /** If the error was caused by an invalid byte, returns the offset and offending byte. */
  invalidByteInfo(): Array<number> | null
  /** If `true`, the length of the base64 string was invalid. */
  causedByInvalidLength(): boolean
  /**
   * The last non-padding input symbol's encoded 6 bits have nonzero bits that will be discarded.
   * If `true`, this is indicative of corrupted or truncated Base64.
   */
  causedByInvalidLastSymbol(): boolean
  /** If the error was caused by an invalid last symbol, returns the offset and offending byte. */
  invalidLastSymbolInfo(): Array<number> | null
  /**
   * The nature of the padding was not as configured: absent or incorrect when it must be
   * canonical, or present when it must be absent, etc.
   */
  causedByInvalidPadding(): boolean
  toString(): string
}
/** The query contains a term for a `f64`-field, but the value is not a f64. */
export declare class ExpectedFloatError {
  toString(): string
}
/** The query contains a term for a `bool`-field, but the value is not a bool. */
export declare class ExpectedBoolError {
  toString(): string
}
/** It is forbidden queries that are only "excluding". (e.g. -title:pop) */
export declare class AllButQueryForbiddenError {
  toString(): string
}
/** If no default field is declared, running a query without any field specified is forbbidden. */
export declare class NoDefaultFieldDeclaredError {
  toString(): string
}
/** The field searched for is not declared as indexed in the schema. */
export declare class FieldNotIndexedError {
  field(): string
  toString(): string
}
/** A phrase query was requested for a field that does not have any positions indexed. */
export declare class FieldDoesNotHavePositionsIndexedError {
  field(): string
  toString(): string
}
/** A phrase-prefix query requires at least two terms */
export declare class PhrasePrefixRequiresAtLeastTwoTermsError {
  phrase(): string
  tokenizer(): string
  toString(): string
}
/** The tokenizer for the given field is unknown. */
export declare class UnknownTokenizerError {
  tokenizer(): string
  field(): string
  toString(): string
}
/**
 * The query contains a range query with a phrase as one of the bounds. Only terms can be used as
 * bounds.
 */
export declare class RangeMustNotHavePhraseError {
  toString(): string
}
/** The format for the date field is not RFC 3339 compliant. */
export declare class DateFormatError {
  toString(): string
}
/** The format for the facet field is invalid. */
export declare class FacetFormatError {
  toString(): string
}
/** The format for the ip field is invalid. */
export declare class IpFormatError {
  toString(): string
}
/**
 * IndexWriter is the user entry-point to add documents to the index.
 *
 * To create an IndexWriter first create an Index and call the writer() method
 * on the index object.
 */
export declare class IndexWriter {
  /**
   * Add a document to the index.
   *
   * If the indexing pipeline is full, this call may block.
   *
   * Returns an `opstamp`, which is an increasing integer that can be used
   * by the client to align commits with its own document queue.
   * The `opstamp` represents the number of documents that have been added
   * since the creation of the index.
   */
  addDocument(doc: Document): bigint
  /**
   * Helper for the `add_document` method, but passing a json string.
   *
   * If the indexing pipeline is full, this call may block.
   *
   * Returns an `opstamp`, which is an increasing integer that can be used
   * by the client to align commits with its own document queue.
   * The `opstamp` represents the number of documents that have been added
   * since the creation of the index.
   */
  addJson(json: string): bigint
  /**
   * Commits all of the pending changes
   *
   * A call to commit blocks. After it returns, all of the document that
   * were added since the last commit are published and persisted.
   *
   * In case of a crash or an hardware failure (as long as the hard disk is
   * spared), it will be possible to resume indexing from this point.
   *
   * Returns the `opstamp` of the last document that made it in the commit.
   */
  commit(): bigint
  /**
   * Rollback to the last commit
   *
   * This cancels all of the update that happened before after the last
   * commit. After calling rollback, the index is in the same state as it
   * was after the last commit.
   */
  rollback(): bigint
  /** Detect and removes the files that are not used by the index anymore. */
  garbageCollectFiles(): void
  /** Deletes all documents from the index. */
  deleteAllDocuments(): void
  /**
   * The opstamp of the last successful commit.
   *
   * This is the opstamp the index will rollback to if there is a failure
   * like a power surge.
   *
   * This is also the opstamp of the commit that is currently available
   * for searchers.
   */
  get commitOpstamp(): bigint
  /**
   * Delete all documents containing a given term.
   *
   * This method does not parse the given term and it expects the term to be
   * already tokenized according to any tokenizers attached to the field. This
   * can often result in surprising behaviour. For example, if you want to store
   * UUIDs as text in a field, and those values have hyphens, and you use the
   * default tokenizer which removes punctuation, you will not be able to delete
   * a document added with particular UUID, by passing the same UUID to this
   * method. In such workflows where deletions are required, particularly with
   * string values, it is strongly recommended to use the
   * "raw" tokenizer as this will match exactly. In situations where you do
   * want tokenization to be applied, it is recommended to instead use the
   * `delete_documents_by_query` method instead, which will delete documents
   * matching the given query using the same query parser as used in search queries.
   *
   * Args:
   *     field_name: The field name for which we want to filter deleted docs.
   *     field_value: JavaScript value with the value we want to filter.
   *
   * If the field_name is not on the schema raises error.
   * If the field_value is not supported raises error.
   */
  deleteDocumentsByTerm(fieldName: string, fieldValue: unknown): bigint
  /**
   * Delete all documents matching a given query.
   *
   * Args:
   *    query: The query to filter the deleted documents.
   *
   * If the query is not valid raises error.
   * If the query is not supported raises error.
   */
  deleteDocumentsByQuery(query: Query): bigint
  /**
   * If there are some merging threads, blocks until they all finish
   * their work and then drop the `IndexWriter`.
   *
   * This will consume the `IndexWriter`. Further accesses to the
   * object will result in an error.
   */
  waitMergingThreads(): void
}
/**
 * Create a new index object.
 *
 * Args:
 *     schema: The schema of the index.
 *     path: The path where the index should be stored. If
 *         no path is provided, the index will be stored in memory.
 *     reuse: Should we open an existing index if one exists
 *         or always create a new one.
 *
 * If an index already exists it will be opened and reused. Raises error
 * if there was a problem during the opening or creation of the index.
 */
export declare class Index {
  static open(path: string): Index
  constructor(schema: Schema, path?: string | undefined | null, reuse?: boolean | undefined | null)
  /**
   * Create a `IndexWriter` for the index.
   *
   * The writer will be multithreaded and the provided heap size will be
   * split between the given number of threads.
   *
   * Args:
   *     overall_heap_size: The total target heap memory usage of
   *         the writer. Tantivy requires that this can't be less
   *         than 3000000 *per thread*. Lower values will result in more
   *         frequent internal commits when adding documents (slowing down
   *         write progress), and larger values will results in fewer
   *         commits but greater memory usage. The best value will depend
   *         on your specific use case.
   *     num_threads: The number of threads that the writer
   *         should use. If this value is 0, tantivy will choose
   *         automatically the number of threads.
   *
   * Raises error if there was an error while creating the writer.
   */
  writer(heapSize?: number | undefined | null, numThreads?: number | undefined | null): IndexWriter
  /**
   * Configure the index reader.
   *
   * Args:
   *     reload_policy: The reload policy that the
   *         IndexReader should use. Can be `Manual` or `OnCommit`.
   *     num_warmers: The number of searchers that the
   *         reader should create.
   */
  configReader(reloadPolicy?: string | undefined | null, numWarmers?: number | undefined | null): void
  /**
   * Returns a searcher
   *
   * This method should be called every single time a search query is performed.
   * The same searcher must be used for a given query, as it ensures the use of a consistent segment set.
   */
  searcher(): Searcher
  /**
   * Check if the given path contains an existing index.
   * Args:
   *     path: The path where tantivy will search for an index.
   *
   * Returns True if an index exists at the given path, False otherwise.
   *
   * Raises error if the directory cannot be opened.
   */
  static exists(path: string): boolean
  /** The schema of the current index. */
  get schema(): Schema
  /**
   * Update searchers so that they reflect the state of the last .commit().
   *
   * If you set up the the reload policy to be on 'commit' (which is the
   * default) every commit should be rapidly reflected on your IndexReader
   * and you should not need to call reload() at all.
   */
  reload(): void
  /**
   * Parse a query
   *
   * Args:
   *     query: the query, following the tantivy query language.
   *
   *     default_fields_names: A list of fields used to search if no
   *         field is specified in the query.
   */
  parseQuery(query: string, defaultFieldNames?: Array<string> | undefined | null): Query
  /**
   * Register a custom text analyzer by name. (Confusingly,
   * this is one of the places where Tantivy uses 'tokenizer' to refer to a
   * TextAnalyzer instance.)
   *
   */
  registerTokenizer(name: string, analyzer: CrateTextAnalyzer): void
}
/**
 * Represents a facet in Tantivy.
 *
 * A Facet represent a point in a given hierarchy.
 * They are typically represented similarly to a filepath. For instance, an
 * e-commerce website could have a Facet for /electronics/tv_and_video/led_tv.
 *
 * A document can be associated to any number of facets. The hierarchy
 * implicitely imply that a document belonging to a facet also belongs to the
 * ancestor of its facet. In the example above, /electronics/tv_and_video/
 * and /electronics.
 *
 * Example:
 * ```javascript
 * const facet = Facet.fromString("/category/electronics/smartphones");
 * console.log(facet.toPathStr()); // "/category/electronics/smartphones"
 * ```
 */
export declare class Facet {
  /** Creates a `Facet` from its binary representation. */
  static fromEncoded(encodedBytes: Array<number>): Facet
  /** Create a new instance of the "root facet" Equivalent to /. */
  static root(): Facet
  /** Returns true if the facet is the root facet /. */
  get isRoot(): boolean
  /**
   * Returns true if another Facet is a subfacet of this facet.
   *
   * @param other - The Facet that we should check if this facet is a subset of.
   * @returns True if this facet is a prefix of the other
   */
  isPrefixOf(other: Facet): boolean
  /**
   * Create a Facet object from a string.
   *
   * @param facet_string - The string that contains a facet.
   * @returns The created Facet.
   */
  static fromString(facetString: string): Facet
  /**
   * Create a facet from an array of path segments.
   *
   * @param path - Array of path segments (e.g., ["category", "electronics", "phones"])
   * @returns A new Facet instance
   */
  static fromPath(path: Array<string>): Facet
  /**
   * Returns the list of `segments` that forms a facet path.
   *
   * For instance `//europe/france` becomes `["europe", "france"]`.
   * @returns Array of path segments
   */
  toPath(): Array<string>
  /**
   * Returns the facet string representation.
   *
   * @returns The facet path as a string
   */
  toPathStr(): string
  /**
   * Convert the facet to its string representation.
   *
   * @returns The facet path as a string
   */
  toString(): string
}
/**
 * Represents an explanation of how a document matched a query.
 * This provides detailed scoring information and query analysis.
 */
export declare class Explanation {
  /**
   * Returns a JSON representation of the explanation.
   * This contains detailed information about how the document matched the query
   * and how the score was calculated.
   */
  toJson(): string
  /** Returns a string representation of the explanation. */
  toString(): string
  /** Gets the score value from the explanation. */
  value(): number
}
